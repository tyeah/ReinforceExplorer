{
        "env": "function",
        "env_config" : {
            "func": "simplenn",
            "action": "params",
            "opt_method": "sgd",
            "action_multiplier": [0.01],
            "state": "loss",
            "stop_grad": 1e-1,
            "base_lr": 0.001,
            "batch_size": 100,
            "max_iter": 2000,
            "params_keep_iter": 1
        },
        "agent": "ddpg_cont",
        "MAX_EPISODES": 1000000,
        "MAX_STEPS": 500000,
        "EPISODES_BEFORE_RESET": 10,
        "discount_rate": 0.99,
        "tau": 0.00001,
        "reg_param": 1e-3,
        "l2": 0.001,
        "init_learning_rate": 1e-4,
        "init_exp_rate": 0.00000001,
        "anneal_step_exp": 200,
        "anneal_step_lr": 200,
        "anneal_base_exp": 0.99,
        "anneal_base_lr": 1,
        "min_lr": 1e-6,
        "min_exp": 0,
        "clip_norm": 5,
        "store_eps": 1,
        "store_size": 50,
        "memory_size": 128,
        "batch_size": 32,
        "save_step": 500000,
        "log_step": 20,
        "estimator_params": {
            "policy_network": {
                "name": "fc", 
                "rnn_preprocess": false,
                "num_hids": [20, 20],
                "num_features": 10,
                "trainable": true
             },
            "value_network": {
                "name": "fc_action", 
                "rnn_preprocess": false,
                "num_hids": [20, 20],
                "num_features": 10,
                "trainable": true
             }
        },
        "inner_state_params": {
            "name": "multi_step_inner_state",
            "num_steps": 10
        }
}
